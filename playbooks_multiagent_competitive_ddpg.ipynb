{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abrarfrahman/playbooks-demo/blob/main/playbooks_multiagent_competitive_ddpg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meUugrwOWCTd"
      },
      "source": [
        "\n",
        "# Playbooks for Collaborative Intelligence: Investigating Misaligned Behaviors in Multi-Agent Systems Using Sports Analytics\n",
        "**Author**: [Abrar Rahman](https://abrarrahman.com/)\n",
        "\n",
        "**Forked from tutorial by**: [Matteo Bettini](https://github.com/matteobettini) at [Cambridge's Prorok Lab](https://proroklab.org/wp/)\n",
        "\n",
        ".. seealso::\n",
        "   The [BenchMARL](https://github.com/facebookresearch/BenchMARL)_ library provides state-of-the-art\n",
        "   implementations of MARL algorithms using TorchRL.\n",
        "\n",
        "We will use the *football* environment from the\n",
        "[VMAS](https://arxiv.org/abs/1706.02275)_. This environment is part\n",
        "of a set called [MultiAgentParticleEnvironments (MPE)](https://github.com/openai/multiagent-particle-envs)_\n",
        "introduced with the paper.\n",
        "\n",
        "There are currently multiple simulators providing MPE environments.\n",
        "We provide flexibility to train this environment in TorchRL using *either*:\n",
        "\n",
        "- [PettingZoo](https://pettingzoo.farama.org/)_, in the traditional CPU version of the environment;\n",
        "- [VMAS](https://github.com/proroklab/VectorizedMultiAgentSimulator)_, which provides a vectorized implementation in PyTorch,\n",
        "  able to simulate multiple environments on a GPU to speed up computation.\n",
        "\n",
        "The `football` simulation is only available on VMAS, so sample code has been provided to run a PettingZoo enviornment for `simple_tag_v3` as a proof of concept."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alwBPVw9WCTe"
      },
      "source": [
        "Deep Deterministic Policy Gradient (DDPG) is an off-policy actor-critic algorithm\n",
        "where a deterministic policy is optimised using the gradients from the critic network.\n",
        "For more information, see the [Deep Deterministic Policy Gradients](https://arxiv.org/abs/1509.02971) paper.\n",
        "This kind of algorithm is typicall trained off-policy. For more info on off-policy learning see\n",
        "*Sutton, Richard S., and Andrew G. Barto. Reinforcement learning: An introduction. MIT press, 2018*.\n",
        "\n",
        ".. figure:: https://pytorch.s3.amazonaws.com/torchrl/github-artifacts/img/off-policy-vmas-loop-min.png\n",
        "   :alt: Off-policy learning\n",
        "\n",
        "   Off-policy learning\n",
        "\n",
        "This approach has been extended to multi-agent learning in [Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments](https://arxiv.org/abs/1706.02275)_,\n",
        "which introduces the Multi Agent DDPG (MADDPG) algorithm.\n",
        "In multi-agent settings, things are a bit different. We now have multiple policies $\\mathbf{\\pi}$,\n",
        "one for each agent. Policies are typically local and decentralised. This means that\n",
        "the policy for a single agent will output an action for that agent based only on its observation.\n",
        "In the MARL literature, this is referred to as **decentralised execution**.\n",
        "On the other hand, different formulations exist for the critic, mainly:\n",
        "\n",
        "- In [MADDPG](https://arxiv.org/abs/1706.02275) the critic is centralised and takes as input the global state and global action\n",
        "  of the system. The global state can be a global observation or simply the concatenation of the agents' observation.\n",
        "  The global action is the concatenation of agent actions. MADDPG\n",
        "  can be used in contexts where **centralised training** is performed as it needs access to global information.\n",
        "- In IDDPG, the critic takes as input just the observation and action of one agent.\n",
        "  This allows **decentralised training** as both the critic and the policy will only need local\n",
        "  information to compute their outputs.\n",
        "\n",
        "Centralised critics help overcome the non-stationary of multiple agents learning concurrently, but,\n",
        "on the other hand, they may be impacted by their large input space.\n",
        "\n",
        "\n",
        "The structure of this notebook is as follows:\n",
        "\n",
        "1. Initially, we will establish a set of hyperparameters for use.\n",
        "\n",
        "2. Subsequently, we will construct a multi-agent environment, utilizing TorchRL's\n",
        "   wrapper for either PettingZoo or VMAS.\n",
        "\n",
        "3. Following that, we will formulate the policy and critic networks, discussing the effects of various choices on\n",
        "   parameter sharing and critic centralization.\n",
        "\n",
        "4. Afterwards, we will create the sampling collector and the replay buffer.\n",
        "\n",
        "5. Bracket simulation, aggregating and computing team- and agent-level metrics to generate \"box scores\"\n",
        "\n",
        "6. Visualization and analysis\n",
        "\n",
        "If you are operating this in Colab or on a machine with a GUI, you will also have the opportunity\n",
        "to render and visualize your own trained policy before and after the training process.\n",
        "\n",
        "Import our dependencies:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torchrl\n",
        "!pip3 install vmas\n",
        "!pip3 install pettingzoo[mpe]==1.24.3\n",
        "!pip3 install tqdm\n",
        "!pip3 install av\n",
        "!apt-get install python3-opengl"
      ],
      "metadata": {
        "id": "uVxWzUj3WUMS",
        "outputId": "2859188a-f4bb-4ac6-da97-5b912b31a1a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchrl in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: torch>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from torchrl) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchrl) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchrl) (24.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from torchrl) (3.1.0)\n",
            "Requirement already satisfied: tensordict>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from torchrl) (0.6.2)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from tensordict>=0.6.0->torchrl) (3.10.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.5.0->torchrl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.5.0->torchrl) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.5.0->torchrl) (3.0.2)\n",
            "Requirement already satisfied: vmas in /usr/local/lib/python3.10/dist-packages (1.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vmas) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from vmas) (2.5.1+cu121)\n",
            "Requirement already satisfied: pyglet<=1.5.27 in /usr/local/lib/python3.10/dist-packages (from vmas) (1.5.27)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from vmas) (0.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from vmas) (1.17.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->vmas) (3.1.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->vmas) (0.0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->vmas) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->vmas) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->vmas) (3.0.2)\n",
            "Requirement already satisfied: pettingzoo==1.24.3 in /usr/local/lib/python3.10/dist-packages (from pettingzoo[mpe]==1.24.3) (1.24.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo==1.24.3->pettingzoo[mpe]==1.24.3) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo==1.24.3->pettingzoo[mpe]==1.24.3) (1.0.0)\n",
            "Requirement already satisfied: pygame==2.3.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo[mpe]==1.24.3) (2.3.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo==1.24.3->pettingzoo[mpe]==1.24.3) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo==1.24.3->pettingzoo[mpe]==1.24.3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo==1.24.3->pettingzoo[mpe]==1.24.3) (0.0.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.10/dist-packages (14.0.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-opengl is already the newest version (3.1.5+dfsg-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4k_K049pWCTe"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import tempfile\n",
        "\n",
        "import torch\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from tensordict import TensorDictBase\n",
        "\n",
        "from tensordict.nn import TensorDictModule, TensorDictSequential\n",
        "from torch import multiprocessing\n",
        "\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data import LazyMemmapStorage, RandomSampler, ReplayBuffer\n",
        "\n",
        "from torchrl.envs import (\n",
        "    check_env_specs,\n",
        "    ExplorationType,\n",
        "    PettingZooEnv,\n",
        "    RewardSum,\n",
        "    set_exploration_type,\n",
        "    TransformedEnv,\n",
        "    VmasEnv,\n",
        ")\n",
        "\n",
        "from torchrl.modules import (\n",
        "    AdditiveGaussianModule,\n",
        "    MultiAgentMLP,\n",
        "    ProbabilisticActor,\n",
        "    TanhDelta,\n",
        ")\n",
        "\n",
        "from torchrl.objectives import DDPGLoss, SoftUpdate, ValueEstimators\n",
        "\n",
        "from torchrl.record import CSVLogger, PixelRenderTransform, VideoRecorder\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if we're building the doc, in which case disable video rendering\n",
        "try:\n",
        "    is_sphinx = __sphinx_build__\n",
        "except NameError:\n",
        "    is_sphinx = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFvCZ2KFWCTf"
      },
      "source": [
        "## Define Hyperparameters\n",
        "\n",
        "We set the hyperparameters for our tutorial.\n",
        "Depending on the resources\n",
        "available, one may choose to execute the policy and the simulator on GPU or on another\n",
        "device.\n",
        "You can tune some of these values to adjust the computational requirements.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLpitqVtWCTf"
      },
      "outputs": [],
      "source": [
        "# Seed\n",
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Devices\n",
        "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
        "device = (\n",
        "    torch.device(0)\n",
        "    if torch.cuda.is_available() and not is_fork\n",
        "    else torch.device(\"cpu\")\n",
        ")\n",
        "\n",
        "# Sampling\n",
        "frames_per_batch = 1_000  # Number of team frames collected per sampling iteration\n",
        "n_iters = 64  # Number of sampling and training iterations\n",
        "total_frames = frames_per_batch * n_iters\n",
        "\n",
        "# We will stop training the evaders after this many iterations,\n",
        "# should be 0 <= iteration_when_stop_training_evaders <= n_iters\n",
        "iteration_when_stop_training_evaders = n_iters // 2\n",
        "\n",
        "# Replay buffer\n",
        "memory_size = 1_000_000  # The replay buffer of each group can store this many frames\n",
        "\n",
        "# Training\n",
        "n_optimiser_steps = 100  # Number of optimization steps per training iteration\n",
        "train_batch_size = 128  # Number of frames trained in each optimiser step\n",
        "lr = 3e-4  # Learning rate\n",
        "max_grad_norm = 1.0  # Maximum norm for the gradients\n",
        "\n",
        "# DDPG\n",
        "gamma = 0.99  # Discount factor\n",
        "polyak_tau = 0.005  # Tau for the soft-update of the target network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2wuyS3kWCTf"
      },
      "source": [
        "## Environment\n",
        "\n",
        "Multi-agent environments simulate multiple agents interacting with the world.\n",
        "TorchRL API allows integrating various types of multi-agent environment flavors.\n",
        "In this tutorial we will focus on environments where multiple agent groups interact in parallel.\n",
        "That is: at every step all agents will get an observation and take an action synchronously.\n",
        "\n",
        "Furthermore, the TorchRL MARL API allows to separate agents into groups. Each group will be a separate entry in the\n",
        "tensordict. The data of agents within a group is stacked together. Therefore, by choosing how to group your agents,\n",
        "you can decide which data is stacked/kept as separate entries.\n",
        "The grouping strategy can be specified at construction in environments like VMAS and PettingZoo.\n",
        "For more info on grouping, see :class:`~torchrl.envs.utils.MarlGroupMapType`.\n",
        "\n",
        "\n",
        "In this scenario, a team of ``n_blue_agents`` play football against a team of ``n_red_agents``. The boolean parameters ``ai_blue_agents`` and ``ai_red_agents`` specify whether each team is controlled by action inputs or a programmed AI. Consequently, football can be treated as either a cooperative or competitive task. The reward in this scenario can be tuned with ``dense_reward_ratio``, where a value of 0 denotes a fully sparse reward (1 for a goal scored, -1 for a goal conceded), and 1 denotes a fully dense reward (based on the the difference of the \"attacking value\" of each team, which considers the distance from the ball to the goal and the presence of open dribbling/shooting lanes to the goal). Every agent observes its position, velocity, relative position to the ball, and relative velocity to the ball. The episode terminates when one team scores a goal.\n",
        "\n",
        "\n",
        "Simulator Differences (PettingZoo vs. VMAS):\n",
        "- The PettingZoo and VMAS versions of any given environment might differ slightly in how they handle certain aspects of the game, such as rewards, ball physics, and player movement.\n",
        "- These differences can influence the training dynamics and performance of the agents.\n",
        "- You might observe variations in reward structures and the strategies that agents develop during training depending on the chosen simulator.\n",
        "\n",
        "We will now instantiate the environment.\n",
        "For this tutorial, we will limit the episodes to ``max_steps``, after which the terminated flag is set. This is\n",
        "functionality is already provided in the PettingZoo and VMAS simulators but the TorchRL :class:`~torchrl.envs.transforms.StepCounter`\n",
        "transform could alternatively be used.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ti0r1xjpWCTg"
      },
      "outputs": [],
      "source": [
        "max_steps = 100  # Environment steps before done\n",
        "\n",
        "# Scenario 2: simple_tag\n",
        "n_chasers = 2\n",
        "n_evaders = 1\n",
        "n_obstacles = 2\n",
        "\n",
        "use_vmas = True  # Set this to True for a great performance speedup\n",
        "\n",
        "if not use_vmas:\n",
        "    base_env = PettingZooEnv(\n",
        "        task=\"simple_tag_v3\",\n",
        "        parallel=True,  # Use the Parallel version\n",
        "        seed=seed,\n",
        "        continuous_actions=True,\n",
        "        num_good=n_evaders,\n",
        "        # Scenario specific\n",
        "        num_adversaries=n_chasers,\n",
        "        num_obstacles=n_obstacles,\n",
        "        max_cycles=max_steps,\n",
        "    )\n",
        "else:\n",
        "    num_vmas_envs = (\n",
        "        frames_per_batch // max_steps\n",
        "    )  # Number of vectorized environments. frames_per_batch collection will be divided among these environments\n",
        "    base_env = VmasEnv(\n",
        "        scenario=\"football\",\n",
        "        num_envs=num_vmas_envs,\n",
        "        continuous_actions=True,\n",
        "        max_steps=max_steps,\n",
        "        device=device,\n",
        "        seed=seed,\n",
        "        # Add params here, based off this https://github.com/proroklab/VectorizedMultiAgentSimulator/blob/VMAS-1.3.3/vmas/scenarios/football.py\n",
        "        # For now, we'll stick to the defaults\n",
        "    )\n",
        "\n",
        "    \"\"\" # Scenario 2: simple_tag\n",
        "    base_env = VmasEnv(\n",
        "        scenario=\"simple_tag\",\n",
        "        num_envs=num_vmas_envs,\n",
        "        continuous_actions=True,\n",
        "        max_steps=max_steps,\n",
        "        device=device,\n",
        "        seed=seed,\n",
        "        # Scenario specific\n",
        "        num_good_agents=n_evaders,\n",
        "        num_adversaries=n_chasers,\n",
        "        num_landmarks=n_obstacles,\n",
        "    )\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCDk8hUxWCTg"
      },
      "source": [
        "### Group map\n",
        "\n",
        "PettingZoo and VMAS environments use the TorchRL MARL grouping API.\n",
        "We can access the group map, mapping each group to the agents in it, as follows:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqdJh5IzWCTg",
        "outputId": "fc5a6939-c24c-4460-e895-7771fb6e57d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "group_map: {'agent_blue': ['agent_blue_0', 'agent_blue_1', 'agent_blue_2']}\n"
          ]
        }
      ],
      "source": [
        "print(f\"group_map: {base_env.group_map}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izhRJDFlWCTg"
      },
      "source": [
        "As we can see it contains one group by default: the blue agents.\n",
        "\n",
        "The environment is not only defined by its simulator and transforms, but also\n",
        "by a series of metadata that describe what can be expected during its\n",
        "execution.\n",
        "For efficiency purposes, TorchRL is quite stringent when it comes to\n",
        "environment specs, but you can easily check that your environment specs are\n",
        "adequate.\n",
        "In our example, the simulator wrapper takes care of setting the proper specs for your base_env, so\n",
        "you should not have to care about this.\n",
        "\n",
        "There are four specs to look at:\n",
        "\n",
        "- ``action_spec`` defines the action space;\n",
        "- ``reward_spec`` defines the reward domain;\n",
        "- ``done_spec`` defines the done domain;\n",
        "- ``observation_spec`` which defines the domain of all other outputs from environment steps;\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDNq6FaFWCTh",
        "outputId": "89841f4b-d6f6-47eb-a4b5-01e44868445b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_spec: Composite(\n",
            "    agent_blue: Composite(\n",
            "        action: BoundedContinuous(\n",
            "            shape=torch.Size([10, 3, 2]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 3, 2]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 3, 2]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 3])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10]))\n",
            "reward_spec: Composite(\n",
            "    agent_blue: Composite(\n",
            "        reward: UnboundedContinuous(\n",
            "            shape=torch.Size([10, 3, 1]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 3])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10]))\n",
            "done_spec: Composite(\n",
            "    done: Categorical(\n",
            "        shape=torch.Size([10, 1]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    terminated: Categorical(\n",
            "        shape=torch.Size([10, 1]),\n",
            "        space=CategoricalBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10]))\n",
            "observation_spec: Composite(\n",
            "    agent_blue: Composite(\n",
            "        observation: UnboundedContinuous(\n",
            "            shape=torch.Size([10, 3, 8]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 3, 8]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 3, 8]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10, 3])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10]))\n"
          ]
        }
      ],
      "source": [
        "print(\"action_spec:\", base_env.full_action_spec)\n",
        "print(\"reward_spec:\", base_env.full_reward_spec)\n",
        "print(\"done_spec:\", base_env.full_done_spec)\n",
        "print(\"observation_spec:\", base_env.observation_spec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQizlMTxWCTh"
      },
      "source": [
        "Using the commands just shown we can access the domain of each value.\n",
        "\n",
        "We can see that all specs are structured as a dictionary, with the root always containing the group names.\n",
        "This structure will be followed in all tensordict data coming and going to the environment.\n",
        "Furthermore, the specs of each group have leading shape ``(n_agents_in_that_group)`` (1 for agents, 2 for adversaries),\n",
        "meaning that the tensor data of that group will always have that leading shape (agents within a group have the data stacked).\n",
        "\n",
        "Looking at the ``done_spec``, we can see that there are some keys that are outside of agent groups\n",
        "(``\"done\", \"terminated\", \"truncated\"``), which do not have a leading multi-agent dimension.\n",
        "These keys are shared by all agents and represent the environment global done state used for resetting.\n",
        "By default, like in this case, parallel PettingZoo environments are done when any agent is done, but this behavior\n",
        "can be overridden by setting ``done_on_any`` at PettingZoo environment construction.\n",
        "\n",
        "To quickly access the keys for each of these values in tensordicts, we can simply ask the environment for the\n",
        "respective keys, and\n",
        "we will immediately understand which are per-agent and which shared.\n",
        "This info will be useful in order to tell all other TorchRL components where to find each value\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ybVqhuQWCTh",
        "outputId": "fbb9573d-fc9d-464f-c812-245c37ed5448",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_keys: [('agent_blue', 'action')]\n",
            "reward_keys: [('agent_blue', 'reward')]\n",
            "done_keys: ['done', 'terminated']\n"
          ]
        }
      ],
      "source": [
        "print(\"action_keys:\", base_env.action_keys)\n",
        "print(\"reward_keys:\", base_env.reward_keys)\n",
        "print(\"done_keys:\", base_env.done_keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBQh99tJWCTh"
      },
      "source": [
        "### Transforms\n",
        "\n",
        "We can append any TorchRL transform we need to our environment.\n",
        "These will modify its input/output in some desired way.\n",
        "We stress that, in multi-agent contexts, it is paramount to provide explicitly the keys to modify.\n",
        "\n",
        "For example, in this case, we will instantiate a ``RewardSum`` transform which will sum rewards over the episode.\n",
        "We will tell this transform where to find the reset keys for each reward key.\n",
        "Essentially we just say that the\n",
        "episode reward of each group should be reset when the ``\"_reset\"`` tensordict key is set, meaning that ``env.reset()``\n",
        "was called.\n",
        "The transformed environment will inherit\n",
        "the device and meta-data of the wrapped environment, and transform these depending on the sequence\n",
        "of transforms it contains.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nt-Q35GUWCTh"
      },
      "outputs": [],
      "source": [
        "env = TransformedEnv(\n",
        "    base_env,\n",
        "    RewardSum(\n",
        "        in_keys=base_env.reward_keys,\n",
        "        reset_keys=[\"_reset\"] * len(base_env.group_map.keys()),\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j2J2z5hWCTh"
      },
      "source": [
        "the :func:`check_env_specs` function runs a small rollout and compares its output against the environment\n",
        "specs. If no error is raised, we can be confident that the specs are properly defined:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khnQUP4TWCTh",
        "outputId": "7b47b455-ce40-4c8f-9492-0e966d528533",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-12-17 16:44:12,793 [torchrl][INFO] check_env_specs succeeded!\n"
          ]
        }
      ],
      "source": [
        "check_env_specs(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te5_AnzOWCTh"
      },
      "source": [
        "### Rollout\n",
        "\n",
        "For fun, let us see what a simple random rollout looks like. You can\n",
        "call `env.rollout(n_steps)` and get an overview of what the environment inputs\n",
        "and outputs look like. Actions will automatically be drawn at random from the action spec\n",
        "domain.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fec6qlStWCTh",
        "outputId": "e74b157d-e231-40ee-c064-e40f50b85d8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rollout of 5 steps: TensorDict(\n",
            "    fields={\n",
            "        agent_blue: TensorDict(\n",
            "            fields={\n",
            "                action: Tensor(shape=torch.Size([10, 5, 3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                observation: Tensor(shape=torch.Size([10, 5, 3, 8]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "            batch_size=torch.Size([10, 5, 3]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([10, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                agent_blue: TensorDict(\n",
            "                    fields={\n",
            "                        episode_reward: Tensor(shape=torch.Size([10, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                        observation: Tensor(shape=torch.Size([10, 5, 3, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                        reward: Tensor(shape=torch.Size([10, 5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "                    batch_size=torch.Size([10, 5, 3]),\n",
            "                    device=cpu,\n",
            "                    is_shared=False),\n",
            "                done: Tensor(shape=torch.Size([10, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                terminated: Tensor(shape=torch.Size([10, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "            batch_size=torch.Size([10, 5]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([10, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([10, 5]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n",
            "Shape of the rollout TensorDict: torch.Size([10, 5])\n"
          ]
        }
      ],
      "source": [
        "n_rollout_steps = 5\n",
        "rollout = env.rollout(n_rollout_steps)\n",
        "print(f\"rollout of {n_rollout_steps} steps:\", rollout)\n",
        "print(\"Shape of the rollout TensorDict:\", rollout.batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZuc6AkvWCTh"
      },
      "source": [
        "We can see that our rollout has ``batch_size`` of ``(n_rollout_steps)``.\n",
        "This means that all the tensors in it will have this leading dimension.\n",
        "\n",
        "Looking more in depth, we can see that the output tensordict can be divided in the following way:\n",
        "\n",
        "- *In the root* (accessible by running ``rollout.exclude(\"next\")`` ) we will find all the keys that are available\n",
        "  after a reset is called at the first timestep. We can see their evolution through the rollout steps by indexing\n",
        "  the ``n_rollout_steps`` dimension. Among these keys, we will find the ones that are different for each agent\n",
        "  in the ``rollout[group_name]`` tensordicts, which will have batch size ``(n_rollout_steps, n_agents_in_group)``\n",
        "  signifying that it is storing the additional agent dimension. The ones outside the group tensordicts\n",
        "  will be the shared ones.\n",
        "- *In the next* (accessible by running ``rollout.get(\"next\")`` ). We will find the same structure as the root with some minor differences highlighted below.\n",
        "\n",
        "In TorchRL the convention is that done and observations will be present in both root and next (as these are\n",
        "available both at reset time and after a step). Action will only be available in root (as there is no action\n",
        "resulting from a step) and reward will only be available in next (as there is no reward at reset time).\n",
        "This structure follows the one in **Reinforcement Learning: An Introduction (Sutton and Barto)** where root represents data at time $t$ and\n",
        "next represents data at time $t+1$ of a world step.\n",
        "\n",
        "\n",
        "### Render a random rollout\n",
        "\n",
        "If you are on Google Colab, or on a machine with OpenGL and a GUI, you can actually render a random rollout.\n",
        "This will give you an idea of what a random policy will achieve in this task, in order to compare it\n",
        "with the policy you will train yourself!\n",
        "\n",
        "To render a rollout, follow the instructions in the *Render* section at the end of this tutorial\n",
        "and just remove the line ``policy=agents_exploration_policy`` from ``env.rollout()``.\n",
        "\n",
        "\n",
        "## Policy\n",
        "\n",
        "DDPG utilises a deterministic policy. This means that our\n",
        "neural network will output the action to take.\n",
        "As the action is continuous, we use a Tanh-Delta distribution to respect the\n",
        "action space boundaries. The only thing that this class does is apply a Tanh transformation to make sure the action\n",
        "is withing the domain bounds.\n",
        "\n",
        "Another important decision we need to make is whether we want the agents within a team to **share the policy parameters**.\n",
        "On the one hand, sharing parameters means that they will all share the same policy, which will allow them to benefit from\n",
        "each other's experiences. This will also result in faster training.\n",
        "On the other hand, it will make them behaviorally *homogenous*, as they will in fact share the same model.\n",
        "For this example, we will enable sharing as we do not mind the homogeneity and can benefit from the computational\n",
        "speed, but it is important to always think about this decision in your own problems!\n",
        "\n",
        "We design the policy in three steps.\n",
        "\n",
        "**First**: define a neural network ``n_obs_per_agent`` -> ``n_actions_per_agents``\n",
        "\n",
        "For this we use the ``MultiAgentMLP``, a TorchRL module made exactly for\n",
        "multiple agents, with much customization available.\n",
        "\n",
        "We will define a different policy for each group and store them in a dictionary.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKA-fpmFWCTh"
      },
      "outputs": [],
      "source": [
        "policy_modules = {}\n",
        "for group, agents in env.group_map.items():\n",
        "    share_parameters_policy = True  # Can change this based on the group\n",
        "\n",
        "    policy_net = MultiAgentMLP(\n",
        "        n_agent_inputs=env.observation_spec[group, \"observation\"].shape[\n",
        "            -1\n",
        "        ],  # n_obs_per_agent\n",
        "        n_agent_outputs=env.full_action_spec[group, \"action\"].shape[\n",
        "            -1\n",
        "        ],  # n_actions_per_agents\n",
        "        n_agents=len(agents),  # Number of agents in the group\n",
        "        centralised=False,  # the policies are decentralised (i.e., each agent will act from its local observation)\n",
        "        share_params=share_parameters_policy,\n",
        "        device=device,\n",
        "        depth=2,\n",
        "        num_cells=256,\n",
        "        activation_class=torch.nn.Tanh,\n",
        "    )\n",
        "\n",
        "    # Wrap the neural network in a :class:`~tensordict.nn.TensorDictModule`.\n",
        "    # This is simply a module that will read the ``in_keys`` from a tensordict, feed them to the\n",
        "    # neural networks, and write the\n",
        "    # outputs in-place at the ``out_keys``.\n",
        "\n",
        "    policy_module = TensorDictModule(\n",
        "        policy_net,\n",
        "        in_keys=[(group, \"observation\")],\n",
        "        out_keys=[(group, \"param\")],\n",
        "    )  # We just name the input and output that the network will read and write to the input tensordict\n",
        "    policy_modules[group] = policy_module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqtmtIGDWCTh"
      },
      "source": [
        "**Second**: wrap the :class:`~tensodrdict.nn.TensorDictModule` in a :class:`~torchrl.modules.ProbabilisticActor`\n",
        "\n",
        "We now need to build the TanhDelta distribution.\n",
        "We instruct the :class:`~torchrl.modules.ProbabilisticActor`\n",
        "class to build a :class:`~torchrl.modules.TanhDelta` out of the policy action\n",
        "parameters. We also provide the minimum and maximum values of this\n",
        "distribution, which we gather from the environment specs.\n",
        "\n",
        "The name of the ``in_keys`` (and hence the name of the ``out_keys`` from\n",
        "the :class:`TensorDictModule` above) has to end with the\n",
        ":class:`~torchrl.modules.TanhDelta` distribution constructor keyword arguments (param).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxsUWGLbWCTh"
      },
      "outputs": [],
      "source": [
        "policies = {}\n",
        "for group, _agents in env.group_map.items():\n",
        "    policy = ProbabilisticActor(\n",
        "        module=policy_modules[group],\n",
        "        spec=env.full_action_spec[group, \"action\"],\n",
        "        in_keys=[(group, \"param\")],\n",
        "        out_keys=[(group, \"action\")],\n",
        "        distribution_class=TanhDelta,\n",
        "        distribution_kwargs={\n",
        "            \"low\": env.full_action_spec[group, \"action\"].space.low,\n",
        "            \"high\": env.full_action_spec[group, \"action\"].space.high,\n",
        "        },\n",
        "        return_log_prob=False,\n",
        "    )\n",
        "    policies[group] = policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9jS0KmlWCTi"
      },
      "source": [
        "**Third**: Exploration\n",
        "\n",
        "Since the DDPG policy is deterministic, we need a way to perform exploration during collection.\n",
        "\n",
        "For this purpose, we need to append an exploration layer to our policies before passing them to the collector.\n",
        "In this case we use a :class:`~torchrl.modules.AdditiveGaussianModule`, which adds gaussian noise to our action\n",
        "(and clamps it if the noise makes the action out of bounds).\n",
        "\n",
        "This exploration wrapper uses a ``sigma`` parameter which is multiplied by the noise to determine its magnitude.\n",
        "Sigma can be annealed throughout training to reduce exploration.\n",
        "Sigma will go from ``sigma_init`` to ``sigma_end`` in ``annealing_num_steps``.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn2w3kUaWCTi"
      },
      "outputs": [],
      "source": [
        "exploration_policies = {}\n",
        "for group, _agents in env.group_map.items():\n",
        "    exploration_policy = TensorDictSequential(\n",
        "        policies[group],\n",
        "        AdditiveGaussianModule(\n",
        "            spec=policies[group].spec,\n",
        "            annealing_num_steps=total_frames\n",
        "            // 2,  # Number of frames after which sigma is sigma_end\n",
        "            action_key=(group, \"action\"),\n",
        "            sigma_init=0.9,  # Initial value of the sigma\n",
        "            sigma_end=0.1,  # Final value of the sigma\n",
        "        ),\n",
        "    )\n",
        "    exploration_policies[group] = exploration_policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogsD_h0mWCTi"
      },
      "source": [
        "## Critic network\n",
        "\n",
        "The critic network is a crucial component of the DDPG algorithm, even though it\n",
        "isn't used at sampling time. This module will read the observations & actions taken and\n",
        "return the corresponding value estimates.\n",
        "\n",
        "As before, one should think carefully about the decision of **sharing the critic parameters** within an agent group.\n",
        "In general, parameter sharing will grant faster training convergence, but there are a few important\n",
        "considerations to be made:\n",
        "\n",
        "- Sharing is not recommended when agents have different reward functions, as the critics will need to learn\n",
        "  to assign different values to the same state (e.g., in mixed cooperative-competitive settings).\n",
        "  In this case, since the two groups are already using separate networks, the sharing decision only applies\n",
        "  for agents within a group, which we already know have the same reward function.\n",
        "- In decentralised training settings, sharing cannot be performed without additional infrastructure to\n",
        "  synchronise parameters.\n",
        "\n",
        "In all other cases where the reward function (to be differentiated from the reward) is the same for all agents\n",
        "in a group (as in the current scenario),\n",
        "sharing can provide improved performance. This can come at the cost of homogeneity in the agent strategies.\n",
        "In general, the best way to know which choice is preferable is to quickly experiment both options.\n",
        "\n",
        "Here is also where we have to choose between **MADDPG and IDDPG**:\n",
        "\n",
        "- With MADDPG, we will obtain a central critic with full-observability\n",
        "  (i.e., it will take all the concatenated global agent observations and actions as input).\n",
        "  We can do this because we are in a simulator\n",
        "  and training is centralised.\n",
        "- With IDDPG, we will have a local decentralised critic, just like the policy.\n",
        "\n",
        "In any case, the critic output will have shape ``(..., n_agents_in_group, 1)``.\n",
        "If the critic is centralised and shared,\n",
        "all the values along the ``n_agents_in_group`` dimension will be identical.\n",
        "\n",
        "As with the policy, we create a critic network for each group and store them in a dictionary.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNCMB0a6WCTi"
      },
      "outputs": [],
      "source": [
        "critics = {}\n",
        "for group, agents in env.group_map.items():\n",
        "    share_parameters_critic = True  # Can change for each group\n",
        "    MADDPG = True  # IDDPG if False, can change for each group\n",
        "\n",
        "    # This module applies the lambda function: reading the action and observation entries for the group\n",
        "    # and concatenating them in a new ``(group, \"obs_action\")`` entry\n",
        "    cat_module = TensorDictModule(\n",
        "        lambda obs, action: torch.cat([obs, action], dim=-1),\n",
        "        in_keys=[(group, \"observation\"), (group, \"action\")],\n",
        "        out_keys=[(group, \"obs_action\")],\n",
        "    )\n",
        "\n",
        "    critic_module = TensorDictModule(\n",
        "        module=MultiAgentMLP(\n",
        "            n_agent_inputs=env.observation_spec[group, \"observation\"].shape[-1]\n",
        "            + env.full_action_spec[group, \"action\"].shape[-1],\n",
        "            n_agent_outputs=1,  # 1 value per agent\n",
        "            n_agents=len(agents),\n",
        "            centralised=MADDPG,\n",
        "            share_params=share_parameters_critic,\n",
        "            device=device,\n",
        "            depth=2,\n",
        "            num_cells=256,\n",
        "            activation_class=torch.nn.Tanh,\n",
        "        ),\n",
        "        in_keys=[(group, \"obs_action\")],  # Read ``(group, \"obs_action\")``\n",
        "        out_keys=[\n",
        "            (group, \"state_action_value\")\n",
        "        ],  # Write ``(group, \"state_action_value\")``\n",
        "    )\n",
        "\n",
        "    critics[group] = TensorDictSequential(\n",
        "        cat_module, critic_module\n",
        "    )  # Run them in sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEoHWmQQWCTi"
      },
      "source": [
        "Let us try our policy and critic modules. As pointed earlier, the usage of\n",
        ":class:`~tensordict.nn.TensorDictModule` makes it possible to directly read the output\n",
        "of the environment to run these modules, as they know what information to read\n",
        "and where to write it.\n",
        "\n",
        "We can see that after each group's networks are run their output keys are added to the data under the\n",
        "group entry.\n",
        "\n",
        "**From this point on, the multi-agent-specific components have been instantiated, and we will simply use the same\n",
        "components as in single-agent learning. Isn't this fantastic?**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KhX4kS_WCTi",
        "outputId": "499c3604-6edc-40b6-b01b-fde4c7debeae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running value and policy for group 'agent_blue': TensorDict(\n",
            "    fields={\n",
            "        agent_blue: TensorDict(\n",
            "            fields={\n",
            "                action: Tensor(shape=torch.Size([10, 3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                obs_action: Tensor(shape=torch.Size([10, 3, 10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                observation: Tensor(shape=torch.Size([10, 3, 8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                param: Tensor(shape=torch.Size([10, 3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                state_action_value: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "            batch_size=torch.Size([10, 3]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([10]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n"
          ]
        }
      ],
      "source": [
        "reset_td = env.reset()\n",
        "for group, _agents in env.group_map.items():\n",
        "    print(\n",
        "        f\"Running value and policy for group '{group}':\",\n",
        "        critics[group](policies[group](reset_td)),\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQt0RcdoWCTi"
      },
      "source": [
        "## Data collector\n",
        "\n",
        "TorchRL provides a set of data collector classes. Briefly, these\n",
        "classes execute three operations: reset an environment, compute an action\n",
        "using the policy and the latest observation, execute a step in the environment, and repeat\n",
        "the last two steps until the environment signals a stop (or reaches a done\n",
        "state).\n",
        "\n",
        "We will use the simplest possible data collector, which has the same output as an environment rollout,\n",
        "with the only difference that it will auto reset done states until the desired frames are collected.\n",
        "\n",
        "We need to feed it our exploration policies. Furthermore, to run the policies from all groups as if they were one,\n",
        "we put them in a sequence. They will not interfere with each other as each group writes and reads keys in different places.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXqXhEHAWCTi"
      },
      "outputs": [],
      "source": [
        "# Put exploration policies from each group in a sequence\n",
        "agents_exploration_policy = TensorDictSequential(*exploration_policies.values())\n",
        "\n",
        "collector = SyncDataCollector(\n",
        "    env,\n",
        "    agents_exploration_policy,\n",
        "    device=device,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=total_frames,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbcm4KXCWCTi"
      },
      "source": [
        "## Replay buffer\n",
        "\n",
        "Replay buffers are a common building piece of off-policy RL algorithms.\n",
        "There are many types of buffers, in this tutorial we use a basic buffer to store and sample tensordict\n",
        "data randomly.\n",
        "\n",
        "This buffer uses :class:`~.data.LazyMemmapStorage`, which stores data on disk.\n",
        "This allows to use the disk memory, but can result in slower sampling as it requires data to be cast to the training device.\n",
        "To store your buffer on the GPU, you can use :class:`~.data.LazyTensorStorage`, passing the desired device.\n",
        "This will result in faster sampling but is subject to the memory constraints of the selected device.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqEx587WWCTi"
      },
      "outputs": [],
      "source": [
        "replay_buffers = {}\n",
        "for group, _agents in env.group_map.items():\n",
        "    replay_buffer = ReplayBuffer(\n",
        "        storage=LazyMemmapStorage(\n",
        "            memory_size\n",
        "        ),  # We will store up to memory_size multi-agent transitions\n",
        "        sampler=RandomSampler(),\n",
        "        batch_size=train_batch_size,  # We will sample batches of this size\n",
        "    )\n",
        "    if device.type != \"cpu\":\n",
        "        replay_buffer.append_transform(lambda x: x.to(device))\n",
        "    replay_buffers[group] = replay_buffer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFdBKZnrWCTi"
      },
      "source": [
        "## Loss function\n",
        "\n",
        "The DDPG loss can be directly imported from TorchRL for convenience using the\n",
        ":class:`~.objectives.DDPGLoss` class. This is the easiest way of utilising DDPG:\n",
        "it hides away the mathematical operations of DDPG and the control flow that\n",
        "goes with it.\n",
        "\n",
        "It is also possible to have different policies for each group.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdAxKDIFWCTi"
      },
      "outputs": [],
      "source": [
        "losses = {}\n",
        "for group, _agents in env.group_map.items():\n",
        "    loss_module = DDPGLoss(\n",
        "        actor_network=policies[group],  # Use the non-explorative policies\n",
        "        value_network=critics[group],\n",
        "        delay_value=True,  # Whether to use a target network for the value\n",
        "        loss_function=\"l2\",\n",
        "    )\n",
        "    loss_module.set_keys(\n",
        "        state_action_value=(group, \"state_action_value\"),\n",
        "        reward=(group, \"reward\"),\n",
        "        done=(group, \"done\"),\n",
        "        terminated=(group, \"terminated\"),\n",
        "    )\n",
        "    loss_module.make_value_estimator(ValueEstimators.TD0, gamma=gamma)\n",
        "\n",
        "    losses[group] = loss_module\n",
        "\n",
        "target_updaters = {\n",
        "    group: SoftUpdate(loss, tau=polyak_tau) for group, loss in losses.items()\n",
        "}\n",
        "\n",
        "optimisers = {\n",
        "    group: {\n",
        "        \"loss_actor\": torch.optim.Adam(\n",
        "            loss.actor_network_params.flatten_keys().values(), lr=lr\n",
        "        ),\n",
        "        \"loss_value\": torch.optim.Adam(\n",
        "            loss.value_network_params.flatten_keys().values(), lr=lr\n",
        "        ),\n",
        "    }\n",
        "    for group, loss in losses.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-k0GdMCWCTi"
      },
      "source": [
        "## Training utils\n",
        "\n",
        "We do have to define two helper functions that we will use in the training loop.\n",
        "They are very simple and do not contain any important logic.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNIXTT4TWCTi"
      },
      "outputs": [],
      "source": [
        "def process_batch(batch: TensorDictBase) -> TensorDictBase:\n",
        "    \"\"\"\n",
        "    If the `(group, \"terminated\")` and `(group, \"done\")` keys are not present, create them by expanding\n",
        "    `\"terminated\"` and `\"done\"`.\n",
        "    This is needed to present them with the same shape as the reward to the loss.\n",
        "    \"\"\"\n",
        "    for group in env.group_map.keys():\n",
        "        keys = list(batch.keys(True, True))\n",
        "        group_shape = batch.get_item_shape(group)\n",
        "        nested_done_key = (\"next\", group, \"done\")\n",
        "        nested_terminated_key = (\"next\", group, \"terminated\")\n",
        "        if nested_done_key not in keys:\n",
        "            batch.set(\n",
        "                nested_done_key,\n",
        "                batch.get((\"next\", \"done\")).unsqueeze(-1).expand((*group_shape, 1)),\n",
        "            )\n",
        "        if nested_terminated_key not in keys:\n",
        "            batch.set(\n",
        "                nested_terminated_key,\n",
        "                batch.get((\"next\", \"terminated\"))\n",
        "                .unsqueeze(-1)\n",
        "                .expand((*group_shape, 1)),\n",
        "            )\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK8tcslCWCTi"
      },
      "source": [
        "## Training loop\n",
        "We now have all the pieces needed to code our training loop.\n",
        "The steps include:\n",
        "\n",
        "* Collect data for all groups\n",
        "    * Loop over groups\n",
        "        * Store group data in group buffer\n",
        "        * Loop over epochs\n",
        "            * Sample from group buffer\n",
        "            * Compute loss on sampled data\n",
        "            * Back propagate loss\n",
        "            * Optimise\n",
        "        * Repeat\n",
        "    * Repeat\n",
        "* Repeat\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yqdxd2mUWCTi",
        "outputId": "5f970f50-1104-4773-dbfb-ef75cbd321c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "episode_reward_mean_agent_blue = 0:   0%|          | 0/10 [02:14<?, ?it/s]\n",
            "episode_reward_mean_agent_blue = -0.025847619399428368: 100%|██████████| 64/64 [26:00<00:00, 22.63s/it]"
          ]
        }
      ],
      "source": [
        "pbar = tqdm(\n",
        "    total=n_iters,\n",
        "    desc=\", \".join(\n",
        "        [f\"episode_reward_mean_{group} = 0\" for group in env.group_map.keys()]\n",
        "    ),\n",
        ")\n",
        "episode_reward_mean_map = {group: [] for group in env.group_map.keys()}\n",
        "train_group_map = copy.deepcopy(env.group_map)\n",
        "\n",
        "# Training/collection iterations\n",
        "for iteration, batch in enumerate(collector):\n",
        "    current_frames = batch.numel()\n",
        "    batch = process_batch(batch)  # Util to expand done keys if needed\n",
        "    # Loop over groups\n",
        "    for group in train_group_map.keys():\n",
        "        group_batch = batch.exclude(\n",
        "            *[\n",
        "                key\n",
        "                for _group in env.group_map.keys()\n",
        "                if _group != group\n",
        "                for key in [_group, (\"next\", _group)]\n",
        "            ]\n",
        "        )  # Exclude data from other groups\n",
        "        group_batch = group_batch.reshape(\n",
        "            -1\n",
        "        )  # This just affects the leading dimensions in batch_size of the tensordict\n",
        "        replay_buffers[group].extend(group_batch)\n",
        "\n",
        "        for _ in range(n_optimiser_steps):\n",
        "            subdata = replay_buffers[group].sample()\n",
        "            loss_vals = losses[group](subdata)\n",
        "\n",
        "            for loss_name in [\"loss_actor\", \"loss_value\"]:\n",
        "                loss = loss_vals[loss_name]\n",
        "                optimiser = optimisers[group][loss_name]\n",
        "\n",
        "                loss.backward()\n",
        "\n",
        "                # Optional\n",
        "                params = optimiser.param_groups[0][\"params\"]\n",
        "                torch.nn.utils.clip_grad_norm_(params, max_grad_norm)\n",
        "\n",
        "                optimiser.step()\n",
        "                optimiser.zero_grad()\n",
        "\n",
        "            # Soft-update the target network\n",
        "            target_updaters[group].step()\n",
        "\n",
        "        # Exploration sigma anneal update\n",
        "        exploration_policies[group][-1].step(current_frames)\n",
        "\n",
        "    # Stop training a certain group when a condition is met (e.g., number of training iterations)\n",
        "    if iteration == iteration_when_stop_training_evaders:\n",
        "        del train_group_map[\"agent_blue\"] # TODO: be sure to change the key(s) here depending on the scenario you're running!\n",
        "\n",
        "    # Logging\n",
        "    for group in env.group_map.keys():\n",
        "        episode_reward_mean = (\n",
        "            batch.get((\"next\", group, \"episode_reward\"))[\n",
        "                batch.get((\"next\", group, \"done\"))\n",
        "            ]\n",
        "            .mean()\n",
        "            .item()\n",
        "        )\n",
        "        episode_reward_mean_map[group].append(episode_reward_mean)\n",
        "\n",
        "    pbar.set_description(\n",
        "        \", \".join(\n",
        "            [\n",
        "                f\"episode_reward_mean_{group} = {episode_reward_mean_map[group][-1]}\"\n",
        "                for group in env.group_map.keys()\n",
        "            ]\n",
        "        ),\n",
        "        refresh=False,\n",
        "    )\n",
        "    pbar.update()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gqzyUk1WCTn"
      },
      "source": [
        "## Results\n",
        "\n",
        "We can plot the mean reward obtained per episode.\n",
        "\n",
        "To make training last longer, increase the ``n_iters`` hyperparameter.\n",
        "\n",
        "When running this script locally, you may need to close the opened window to\n",
        "proceed with the rest of the screen.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygayJ_tNWCTn",
        "outputId": "baa7a472-8761-44de-c498-66be7033f7e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, axs = plt.subplots(2, 1)\n",
        "for i, group in enumerate(env.group_map.keys()):\n",
        "    axs[i].plot(episode_reward_mean_map[group], label=f\"Episode reward mean {group}\")\n",
        "    axs[i].set_ylabel(\"Reward\")\n",
        "    axs[i].axvline(\n",
        "        x=iteration_when_stop_training_evaders,\n",
        "        label=\"Agent stop training\",\n",
        "        color=\"orange\",\n",
        "    )\n",
        "    axs[i].legend()\n",
        "axs[-1].set_xlabel(\"Training iterations\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZM5GShRWCTn"
      },
      "source": [
        "## Render\n",
        "\n",
        "*Rendering instruction are for VMAS*, aka when running with ``use_vmas=True``.\n",
        "\n",
        "TorchRL offers some utils to record and save rendered videos. You can learn more about these tools\n",
        "`here <Environment-Recorders>`.\n",
        "\n",
        "In the following code-block, we append a transform that will call the :meth:`render` method from the VMAS\n",
        "wrapped environment and save the stack of frames to a `mp4` file which location is determined by the custom\n",
        "logger `video_logger`. Note that this code may require some external dependencies such as torchvision.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN7YjocsWCTn",
        "outputId": "819f3de6-45ca-4baa-845c-f298dcc80c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating rendering env\n",
            "Rendering rollout...\n",
            "Saving the video...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "an integer is required",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-235ee5a65196>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving the video...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0menv_with_render\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Now dump the recorder data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved! Saved directory tree:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mvideo_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_log_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchrl/envs/transforms/transforms.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m     def _reset(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchrl/record/recorder.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, suffix)\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 self.logger.log_video(\n\u001b[0m\u001b[1;32m    254\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                     \u001b[0mvideo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchrl/record/loggers/csv.py\u001b[0m in \u001b[0;36mlog_video\u001b[0;34m(self, name, video, step, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0;34m\"Wrong format of the video tensor. Should be ((N), T, C, H, W)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             )\n\u001b[0;32m--> 198\u001b[0;31m         self.experiment.add_video(\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mvid_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchrl/record/loggers/csv.py\u001b[0m in \u001b[0;36madd_video\u001b[0;34m(self, tag, vid_tensor, global_step, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mvid_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvid_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvid_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_fps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/io/video.py\u001b[0m in \u001b[0;36mwrite_video\u001b[0;34m(filename, video_array, fps, video_codec, options, audio_array, audio_fps, audio_codec, audio_options)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideo_array\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rgb24\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpict_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"NONE\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpacket\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmux\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mav/video/frame.pyx\u001b[0m in \u001b[0;36mav.video.frame.VideoFrame.pict_type.__set__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: an integer is required"
          ]
        }
      ],
      "source": [
        "if use_vmas and not is_sphinx:\n",
        "    # Replace tmpdir with any desired path where the video should be saved\n",
        "    with tempfile.TemporaryDirectory() as tmpdir:\n",
        "        video_logger = CSVLogger(\"vmas_logs\", tmpdir, video_format=\"mp4\")\n",
        "        print(\"Creating rendering env\")\n",
        "        env_with_render = TransformedEnv(env.base_env, env.transform.clone())\n",
        "        env_with_render = env_with_render.append_transform(\n",
        "            PixelRenderTransform(\n",
        "                out_keys=[\"pixels\"],\n",
        "                # the np.ndarray has a negative stride and needs to be copied before being cast to a tensor\n",
        "                preproc=lambda x: x.copy(),\n",
        "                as_non_tensor=True,\n",
        "                # asking for array rather than on-screen rendering\n",
        "                mode=\"rgb_array\",\n",
        "            )\n",
        "        )\n",
        "        env_with_render = env_with_render.append_transform(\n",
        "            VideoRecorder(logger=video_logger, tag=\"vmas_rendered\")\n",
        "        )\n",
        "        with set_exploration_type(ExplorationType.DETERMINISTIC):\n",
        "            print(\"Rendering rollout...\")\n",
        "            env_with_render.rollout(100, policy=agents_exploration_policy)\n",
        "        print(\"Saving the video...\")\n",
        "\n",
        "        env_with_render.transform.dump()  # Now dump the recorder data\n",
        "        print(\"Saved! Saved directory tree:\")\n",
        "        video_logger.print_log_dir()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v4zcC20J5DSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBi5AZrEWCTn"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}